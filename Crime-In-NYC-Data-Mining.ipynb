{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pyspark\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Crime-In-NYC-Data-Mining').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+-------+------------------+------+----+-------+--------------+--------+-------------+------------------------------+-----+-------------+--------------+\n",
      "|_c0|                PARK|        BOROUGH|QUARTER|          CATEGORY|MURDER|RAPE|ROBBERY|FELONY ASSAULT|BURGLARY|GRAND LARCENY|GRAND LARCENY OF MOTOR VEHICLE|TOTAL|CRIME OCCURED|VICIOUS CRIMES|\n",
      "+---+--------------------+---------------+-------+------------------+------+----+-------+--------------+--------+-------------+------------------------------+-----+-------------+--------------+\n",
      "|  0|     PELHAM BAY PARK|          BRONX|      1|ONE ACRE OR LARGER|   0.0| 1.0|    1.0|           0.0|     0.0|          0.0|                           0.0|    2|            1|           1.0|\n",
      "|  1|  VAN CORTLANDT PARK|          BRONX|      1|ONE ACRE OR LARGER|   0.0| 0.0|    2.0|           1.0|     0.0|          0.0|                           0.0|    3|            1|           0.0|\n",
      "|  2|ROCKAWAY BEACH AN...|         QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "|  3|     FRESHKILLS PARK|  STATEN ISLAND|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "|  4|FLUSHING MEADOWS ...|         QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     1.0|          2.0|                           2.0|    5|            1|           0.0|\n",
      "|  5|LATOURETTE PARK &...|  STATEN ISLAND|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "|  6|         MARINE PARK|       BROOKLYN|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          2.0|                           0.0|    2|            1|           0.0|\n",
      "|  7|BELT PARKWAY/SHOR...|BROOKLYN/QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "|  8|          BRONX PARK|          BRONX|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "|  9|FRANKLIN D. ROOSE...|  STATEN ISLAND|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 10|     ALLEY POND PARK|         QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 11|       PROSPECT PARK|       BROOKLYN|      1|ONE ACRE OR LARGER|   0.0| 0.0|    1.0|           0.0|     0.0|          1.0|                           0.0|    2|            1|           0.0|\n",
      "| 12|         FOREST PARK|         QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    1.0|           0.0|     0.0|          0.0|                           0.0|    1|            1|           0.0|\n",
      "| 13|GRAND CENTRAL PAR...|         QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 14|    FERRY POINT PARK|          BRONX|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 15|CONEY ISLAND BEAC...|       BROOKLYN|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 16|     CUNNINGHAM PARK|         QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 17|    RICHMOND PARKWAY|  STATEN ISLAND|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 18|CROSS ISLAND PARKWAY|         QUEENS|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "| 19|    GREAT KILLS PARK|  STATEN ISLAND|      1|ONE ACRE OR LARGER|   0.0| 0.0|    0.0|           0.0|     0.0|          0.0|                           0.0|    0|            0|           0.0|\n",
      "+---+--------------------+---------------+-------+------------------+------+----+-------+--------------+--------+-------------+------------------------------+-----+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing cleaned data\n",
    "df = spark.read.csv('Datasets/good-nyc-park-crime-2016.csv',header=True,inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- PARK: string (nullable = true)\n",
      " |-- BOROUGH: string (nullable = true)\n",
      " |-- QUARTER: integer (nullable = true)\n",
      " |-- CATEGORY: string (nullable = true)\n",
      " |-- MURDER: double (nullable = true)\n",
      " |-- RAPE: double (nullable = true)\n",
      " |-- ROBBERY: double (nullable = true)\n",
      " |-- FELONY ASSAULT: double (nullable = true)\n",
      " |-- BURGLARY: double (nullable = true)\n",
      " |-- GRAND LARCENY: double (nullable = true)\n",
      " |-- GRAND LARCENY OF MOTOR VEHICLE: double (nullable = true)\n",
      " |-- TOTAL: integer (nullable = true)\n",
      " |-- CRIME OCCURED: integer (nullable = true)\n",
      " |-- VICIOUS CRIMES: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing essential packets for data mining\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "murder_indexer = StringIndexer(inputCol='MURDER',outputCol='murder_re')\n",
    "rape_indexer = StringIndexer(inputCol='RAPE',outputCol='rape_re')\n",
    "vicious_crimes_indexer = StringIndexer(inputCol='VICIOUS CRIMES',outputCol='label')\n",
    "\n",
    "\n",
    "murder_encoder = OneHotEncoder(inputCol='murder_re',outputCol='murder_vec')\n",
    "rape_encoder = OneHotEncoder(inputCol='rape_re',outputCol='rape_vec')\n",
    "label_encoder = StringIndexer(inputCol='label',outputCol='label')\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['murder_vec','rape_vec'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[murder_indexer,rape_indexer,vicious_crimes_indexer,murder_encoder,rape_encoder, assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, label: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model = pipeline.fit(df)\n",
    "pipe_df = pipeline_model.transform(df)\n",
    "pipe_df = pipe_df.select('label','features')\n",
    "pipe_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 2773\n",
      "Test Dataset Count: 1843\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = pipe_df.randomSplit([0.6,0.4])\n",
    "print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Coefficients: [0.0,0.0,0.0]\n",
      "Intercept: 0.006491164803461955\n",
      "numIterations: 1\n",
      "objectiveHistory: [0.5]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "|-0.00649116480346...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 0.080306\n",
      "r2: -0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='label',maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train_data)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+\n",
      "|          prediction|label|     features|\n",
      "+--------------------+-----+-------------+\n",
      "|0.006491164803461955|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006491164803461955|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006491164803461955|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006491164803461955|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006491164803461955|  0.0|[1.0,1.0,0.0]|\n",
      "+--------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = -5.27324e-08\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lrModel.transform(test_data)\n",
    "lr_predictions.select(\"prediction\",\"label\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"label\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression\n",
      "+----------+-----+-------------+\n",
      "|prediction|label|     features|\n",
      "+----------+-----+-------------+\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "+----------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0232936\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Regression\n",
    "\n",
    "print(\"Decision Tree Regression\")\n",
    "\n",
    "dec = DecisionTreeRegressor(featuresCol = 'features', labelCol='label', maxBins=32, maxDepth=5)\n",
    "\n",
    "# Fit the model\n",
    "decModel = dec.fit(train_data)\n",
    "\n",
    "predictions = decModel.transform(test_data)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression\n",
      "+--------------------+-----+-------------+\n",
      "|          prediction|label|     features|\n",
      "+--------------------+-----+-------------+\n",
      "|0.001508380488653...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.001508380488653...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.001508380488653...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.001508380488653...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.001508380488653...|  0.0|[1.0,1.0,0.0]|\n",
      "+--------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0447865\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression\n",
    "print(\"Random Forest Regression\")\n",
    "\n",
    "dec = RandomForestRegressor(featuresCol = 'features', labelCol='label', maxBins=32, maxDepth=5)\n",
    "\n",
    "# Fit the model\n",
    "decModel = dec.fit(train_data)\n",
    "\n",
    "predictions = decModel.transform(test_data)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 2773\n",
      "Test Dataset Count: 1843\n"
     ]
    }
   ],
   "source": [
    "train_data_iter2, test_data_iter2 = pipe_df.randomSplit([0.7,0.3])\n",
    "print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Iteration 2\n",
      "Coefficients: [0.0,0.0,0.0]\n",
      "Intercept: 0.006790123456790123\n",
      "numIterations: 1\n",
      "objectiveHistory: [0.5000000000000001]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "|-0.00679012345679...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 0.085798\n",
      "r2: 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Linear Regression - Iteration 2\")\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='label',maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train_data_iter2)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+\n",
      "|          prediction|label|     features|\n",
      "+--------------------+-----+-------------+\n",
      "|0.006790123456790123|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006790123456790123|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006790123456790123|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006790123456790123|  0.0|[1.0,1.0,0.0]|\n",
      "|0.006790123456790123|  0.0|[1.0,1.0,0.0]|\n",
      "+--------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = -0.000164859\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lrModel.transform(test_data_iter2)\n",
    "lr_predictions.select(\"prediction\",\"label\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"label\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression - Iteration 2\n",
      "+----------+-----+-------------+\n",
      "|prediction|label|     features|\n",
      "+----------+-----+-------------+\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "|       0.0|  0.0|[1.0,1.0,0.0]|\n",
      "+----------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Regression\n",
    "\n",
    "print(\"Decision Tree Regression - Iteration 2\")\n",
    "\n",
    "dec = DecisionTreeRegressor(featuresCol = 'features', labelCol='label', maxBins=32, maxDepth=10)\n",
    "\n",
    "# Fit the model\n",
    "decModel = dec.fit(train_data_iter2)\n",
    "\n",
    "predictions = decModel.transform(test_data_iter2)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression - Iteration 2\n",
      "+--------------------+-----+-------------+\n",
      "|          prediction|label|     features|\n",
      "+--------------------+-----+-------------+\n",
      "|0.002020378741551...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.002020378741551...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.002020378741551...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.002020378741551...|  0.0|[1.0,1.0,0.0]|\n",
      "|0.002020378741551...|  0.0|[1.0,1.0,0.0]|\n",
      "+--------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0179271\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression\n",
    "print(\"Random Forest Regression - Iteration 2\")\n",
    "\n",
    "dec = RandomForestRegressor(featuresCol = 'features', labelCol='label', maxBins=32, maxDepth=10)\n",
    "\n",
    "# Fit the model\n",
    "decModel = dec.fit(train_data_iter2)\n",
    "\n",
    "predictions = decModel.transform(test_data_iter2)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "murder_indexer = StringIndexer(inputCol='MURDER',outputCol='murder_re')\n",
    "rape_indexer = StringIndexer(inputCol='RAPE',outputCol='rape_re')\n",
    "vicious_crimes_indexer = StringIndexer(inputCol='VICIOUS CRIMES',outputCol='vicious_crimes_re')\n",
    "total_indexer = StringIndexer(inputCol='TOTAL', outputCol='total_re')\n",
    "crime_occured_indexer = StringIndexer(inputCol='CRIME OCCURED', outputCol='crime_occured_re')\n",
    "category_indexer = StringIndexer(inputCol='CATEGORY', outputCol='category_re')\n",
    "quarter_indexer = StringIndexer(inputCol='QUARTER', outputCol='quarter_re')\n",
    "borough_indexer = StringIndexer(inputCol='BOROUGH', outputCol='label')\n",
    "\n",
    "\n",
    "\n",
    "murder_encoder = OneHotEncoder(inputCol='murder_re',outputCol='murder_vec')\n",
    "rape_encoder = OneHotEncoder(inputCol='rape_re',outputCol='rape_vec')\n",
    "vicious_crimes_encoder = OneHotEncoder(inputCol='vicious_crimes_re',outputCol='vicious_crimes_vec')\n",
    "total_encoder = OneHotEncoder(inputCol='total_re',outputCol='total_vec')\n",
    "crime_occured_encoder = OneHotEncoder(inputCol='crime_occured_re',outputCol='crime_occured_vec')\n",
    "category_encoder = OneHotEncoder(inputCol='category_re',outputCol='category_vec')\n",
    "quarter_encoder = OneHotEncoder(inputCol='quarter_re',outputCol='quarter_vec')\n",
    "label_encoder = StringIndexer(inputCol='label',outputCol='label')\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['murder_vec','rape_vec', 'vicious_crimes_vec', 'total_vec', 'crime_occured_vec', 'category_vec', 'quarter_vec'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(stages=[murder_indexer,rape_indexer,vicious_crimes_indexer,total_indexer,crime_occured_indexer,category_indexer,quarter_indexer,borough_indexer,murder_encoder,rape_encoder,vicious_crimes_encoder,total_encoder,crime_occured_encoder,category_encoder,quarter_encoder,assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, label: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2_model = pipeline2.fit(df)\n",
    "pipe2_df = pipeline2_model.transform(df)\n",
    "pipe2_df = pipe2_df.select('label','features')\n",
    "pipe2_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 2773\n",
      "Test Dataset Count: 1843\n"
     ]
    }
   ],
   "source": [
    "train_data2, test_data2 = pipe2_df.randomSplit([0.6,0.4])\n",
    "print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Iteration 1\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy = 0.287506819421713\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "print(\"Logistic Regression - Iteration 1\")\n",
    "\n",
    "# Instantiate the model.\n",
    "lr_model = LogisticRegression(featuresCol='features',labelCol='label')\n",
    "\n",
    "# Fit the model.\n",
    "lr_model = lr_model.fit(train_data2)\n",
    "\n",
    "# And evaluate the model using the test data.\n",
    "predictions = lr_model.transform(test_data2)\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs Rest Classifer - Iteration 1\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test accuracy = 0.704855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"One vs Rest Classifer - Iteration 1\")\n",
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression(maxIter=5, tol=1E-6, fitIntercept=True)\n",
    "\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(train_data2)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(test_data2)\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# obtain evaluator.\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "# compute the classification error on test data.\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test accuracy = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Iteration 1\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Area Under ROC: 0.49044284380418846\n",
      "Test accuracy = 0.509557\n"
     ]
    }
   ],
   "source": [
    "# create the trainer and set its parameters\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "print(\"Naive Bayes Iteration 1\")\n",
    "nb = NaiveBayes(smoothing=0.4, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train_data2)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test_data2)\n",
    "#predictions.show()\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "#print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "print(\"Test accuracy = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3209\n",
      "Test Dataset Count: 1407\n"
     ]
    }
   ],
   "source": [
    "train_data2_iter2, test_data2_iter2 = pipe2_df.randomSplit([0.7,0.3])\n",
    "print(\"Training Dataset Count: \" + str(train_data2_iter2.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data2_iter2.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Iteration 2\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.2736318407960199\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "print(\"Logistic Regression - Iteration 2\")\n",
    "\n",
    "# Instantiate the model.\n",
    "lr_model = LogisticRegression(featuresCol='features',labelCol='label')\n",
    "\n",
    "# Fit the model.\n",
    "lr_model = lr_model.fit(train_data2_iter2)\n",
    "\n",
    "# And evaluate the model using the test data.\n",
    "predictions = lr_model.transform(test_data2_iter2)\n",
    "\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(20)\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs Rest Classifer - Iteration 2\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test accuracy = 0.725657\n"
     ]
    }
   ],
   "source": [
    "print(\"One vs Rest Classifer - Iteration 2\")\n",
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(train_data2_iter2)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(test_data2_iter2)\n",
    "\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(20)\n",
    "\n",
    "# obtain evaluator.\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "# compute the classification error on test data.\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test accuracy = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Iteration 2\n",
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "|       1.0|  0.0|(36,[0,1,3,5,23,2...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Test Area Under ROC: 0.5211499085288767\n",
      "Test accuracy = 0.47885\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "print(\"Naive Bayes Iteration 2\")\n",
    "nb = NaiveBayes(smoothing=0.8, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train_data2_iter2)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test_data2_iter2)\n",
    "\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(10)\n",
    "\n",
    "\n",
    "\n",
    "# compute accuracy on the test set\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "#print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "print(\"Test accuracy = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
